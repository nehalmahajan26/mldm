import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.datasets import load_iris

data = load_iris()

df = pd.DataFrame(data.data, columns=data.feature_names)

df['target'] = data.target
df.fillna(df.mean(), inplace=True)
print(df)
-----
scaler = StandardScaler()
df_scaled = df.copy()
df_scaled.iloc[:, :-1] = scaler.fit_transform(df.iloc[:, :-1])

train_df, test_df = train_test_split(df_scaled, test_size=0.2, random_state=42, stratify=df['target'])
print(f"Training set shape: {train_df.shape}, Test set shape: {test_df.shape}")
------
#step 2
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import cross_val_score
import numpy as np
# Separate features and target for training set
X_train = train_df.iloc[:, :-1]
y_train = train_df.iloc[:, -1]
dt_classifier = DecisionTreeClassifier(random_state=42)

cv_scores = cross_val_score(dt_classifier, X_train, y_train, cv=5)
avg_accuracy = np.mean(cv_scores)
std_deviation = np.std(cv_scores)


print(f"Cross-Validation Accuracy: {avg_accuracy:.4f}")
print(f"Standard Deviation of Accuracy: {std_deviation:.4f}")

--------
#step-3 - holdout set evaluation
from sklearn.metrics import classification_report, confusion_matrix
dt_classifier.fit(X_train, y_train)
X_test = test_df.iloc[:, :-1]
y_test = test_df.iloc[:, -1]
y_pred = dt_classifier.predict(X_test)
conf_matrix = confusion_matrix(y_test, y_pred)
class_report = classification_report(y_test, y_pred)
print("Confusion Matrix:")
print(conf_matrix)
print("\nClassification Report:")
print(class_report)

-----
# 4. Overfitting Prevention Techniques
# a. Prune the Decision Tree
pruned_dt = DecisionTreeClassifier(
    max_depth=3,
    min_samples_split=4,
    min_samples_leaf=2,
    random_state=42
)
# Fit the pruned decision tree on the training data
pruned_dt.fit(X_train, y_train)
# Predict on the test set
y_pred_pruned = pruned_dt.predict(X_test)
print("\nClassification Report for Pruned Tree:")
print(classification_report(y_test, y_pred_pruned, target_names=data.target_names))

conf_matrix_pruned = confusion_matrix(y_test, y_pred_pruned)
print("Confusion Matrix for Pruned Tree:")
print(conf_matrix_pruned)
param_grid = {
    'max_depth': [None, 2, 3, 4, 5],
    'min_samples_split': [2, 4, 6],
    'min_samples_leaf': [1, 2, 3]
}
grid_search = GridSearchCV(
    estimator=DecisionTreeClassifier(random_state=42),
    param_grid=param_grid,
    cv=5,
    scoring='accuracy',
    n_jobs=-1
)

grid_search.fit(X_train, y_train)

print("\nBest Hyperparameters from GridSearchCV:")
print(grid_search.best_params_)
print(f"Best Cross-Validation Accuracy: {grid_search.best_score_:.4f}")

best_dt = grid_search.best_estimator_
best_dt.fit(X_train, y_train)

y_pred_best = best_dt.predict(X_test)

print("\nClassification Report for Best Model:")
print(classification_report(y_test, y_pred_best, target_names=data.target_names))


conf_matrix_best = confusion_matrix(y_test, y_pred_best)
print("Confusion Matrix for Best Model:")
print(conf_matrix_best)
